# MODE: internal | local
AI_PC_MODE=internal

# Storage
DATA_DIR=./data
SQLITE_PATH=./data/meta.db

# Indexing
# Comma-separated file extensions to extract text from (lowercase, include dot)
INDEX_EXTS=.txt,.md,.pdf,.docx,.xlsx

# Chunking
CHUNK_SIZE=900
CHUNK_OVERLAP=150

# Embeddings (optional; set ENABLE_EMBEDDINGS=true to use)
ENABLE_EMBEDDINGS=false
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# FAISS
FAISS_DIR=./data/faiss

# Internal OpenAI-compatible proxy
INTERNAL_BASE_URL=http://127.0.0.1:4000/v1
INTERNAL_API_KEY=dummy-key
INTERNAL_MODEL=internal-llm-chat

# Local LLM (optional; not bundled by default)
LOCAL_GGUF_PATH=./models/model.gguf
LOCAL_CTX=4096
LOCAL_THREADS=8

# Server
HOST=127.0.0.1
PORT=8000
